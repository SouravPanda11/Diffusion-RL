# Diffusion Policies for Offline Reinforcement Learning â€” *Reimplementation*

This repository is a **from-scratch reimplementation** of the paper:

> **Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning**  
> ðŸ“„ Paper: https://arxiv.org/abs/2208.06193

The original authorsâ€™ implementation can be found here:

> ðŸ”— **Official GitHub Repository:**  
> https://github.com/Zhendong-Wang/Diffusion-Policies-for-Offline-RL

---

The original codebase depends on **D4RL**, which is difficult to install on Windows, relies on deprecated environments, and conflicts with modern Gymnasium/Python setupsâ€”so I rebuilt the entire pipeline **without D4RL**.

Instead: âœ” Trained PPO agents (SB3) â€” âœ” Collected offline datasets â€” âœ” Mixed them into one buffer â€” âœ” Trained diffusion models on the custom dataset

This makes the project: fully reproducible â€” platform-independent â€” free of MuJoCo/D4RL issues â€” simple for students/researchers to run.

---
